#+title: Cost Overrun Codes
# #+SUBTITLE: (Press ~?~ for help; ~n~ and ~p~ for next and previous slide)
#+author: Jonghyun Yun
#+email: jonghyun.yun@gmail.com

# https://orgmode.org/manual/Export-Settings.html#Export-Settings
#+options:   H:10 num:nil toc:nil \n:nil @:t ::t |:t ^:nil ^:{} -:t f:t *:t <:t ':nil -:nil pri:t
#+options:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc

#+startup: overview inlineimages logdone indent

# comment out for reveal.js
#+setupfile: ~/setup/my-theme-readtheorg.setup
#+setupfile: ~/org/latex_header.setup
#+setupfile: ~/org/orgmode_header.setup

#+property: header-args :eval never-export
#+property: header-args:R :exports both :noweb yes
#+property: header-args:matlab :session *MATLAB* :exports results :results output :noweb yes
#+property: header-args:jupyter-python :session *jupyter-cor* :kernel tf :async yes

* Prerequisite
:PROPERTIES:
:header-args:R:          :tangle prerequisite.R
:END:

This section contains code for global =knitr= options and installing and/or loading required packages.
The options are meaningful only if you render this document; otherwise ignore them.
#+name: global_option,include=F
#+begin_src R
  ## Need the knitr package to set chunk options
  library(knitr)

  ## Set knitr options for knitting code into the report:
  ## Print out code (echo)
  ## Save results so that code blocks aren't re-run unless code changes (cache),
  ## or a relevant earlier code block changed (autodep), but don't re-run if the
  ## only thing that changed was the comments (cache.comments)
  ## Align plots center (fig.align)
  ## Don't clutter R output with messages or warnings (message, warning)
  ## This will leave error messages showing up in the knitted report
  opts_chunk$set(echo=TRUE,
                 cache=TRUE, autodep=TRUE, cache.comments=FALSE,
                 fig.align="center",
                 fig.width=12, fig.height=9,
                 message=FALSE, warning=FALSE)
#+end_src

#+RESULTS: global_option,include=F

** CatBoost
For installing ~CatBoost~, see https://catboost.ai/docs/installation/r-installation-binary-installation.html#r-installation-binary-installation.
#+attr_ravel: eval=F
#+begin_src R :eval no :tangle no
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.24.4/catboost-R-Darwin-0.24.4.tgz', INSTALL_opts = c("--no-multiarch"))
#+end_src

** Required packages

The below is a list of required packages. All of them (except ~CatBoost~) can be installed using =packages.install=.

#+name:load
#+attr_ravel: message=F, warning=F
#+begin_src R :results none
require(glmnet)
require(ALEPlot)
## require(data.table)
## require(readr)
require(caret)
require(xgboost)
require(dplyr)
require(Matrix)
require(catboost)
require(caret)
require(stringr)
require(MLmetrics)
## require(fastICA)
require(nnet)
## require(plyr)
require(ggplot2)
require(WeightedROC)
require(ranger)
#+end_src

This is global options, which are included in my =.Rprofile=.
#+begin_src R
## Don't convert text strings to factors with base read functions
options(stringsAsFactors = FALSE)
## Dont' omit NA rows
options(na.action = "na.pass")
#+end_src

#+RESULTS:
# # # # # #
* Custom functions
:PROPERTIES:
:header-args:R:          :tangle custom_function.R
:END:
This section contains custom R functions. These function can also be found in ~custom_function.R~.

- =to_factor= is a function to convert a character vector to a factor vector whose levels are ordered by conditional proportions of =label=.
- =find_continent= is a function to group contries by continents.
- =plot_y=: to draw a scatter plot whose points are marked by label
- =plot_prob=: to draw a scatter plot whose points are marked by prediction probablity
- =mylogit=: to do the logit transformation
- =plot_vimp=: to plot the variable importance
#+begin_src R
wlogloss <- function(y, p, w = rep(1, length(y)) / length(y)) {
  # return weighted log loss
  # y: actual y
  # p: prediction prob
  # w: case weight
  eps <- 1e-15
  p <- pmax(pmin(p, 1 - eps), eps)
  w <- w / sum(w)
  out <- -sum(w * (y * log(p) + (1 - y) * log(1 - p)))
  return(out)
}

order_level <- function(x, label) {
  tab <- table(x, label)
  cp <- tab / apply(tab, 1, sum)
  ll <- row.names(tab[order(cp[, 2]), ])
  return(ll)
}

to_factor <- function(x, label = ytrain) {
  out <- factor(x, levels = order_level(x, label))
  return(out)
}

find_continent <- function(x) {
  if (x %in% c("Panama", "Guatemala", "Honduras", "Dominican-Republic", "El-Salvador", "Columbia", "Nicaragua", "Trinadad&Tobago", "Puerto-Rico", "Haiti", "Peru", "Ecuador", "Jamaica", "Cuba")) {
    out <- "South.America"
  } else if (x %in% c("Japan", "Iran", "Laos", "India", "Outlying-U S (Guam USVI etc)", "Vietnam", "Taiwan", "China", "Cambodia", "Thailand", "South Korea", "Philippines", "Hong Kong")) {
    out <- "Asia"
  } else if (x %in% c("Portugal", "Italy", "Yugoslavia", "Greece", "Poland", "Germany", "England", "Hungary", "Scotland", "France", "Ireland", "Holand-Netherlands")) {
    out <- "Europe"
  } else if (x %in% c("United-States", "Canada", "Mexico")) {
    out <- "North.America"
  } else {
    out <- NA
  }
  return(out)
}

plot_y <- function(x1, x2, point_size = 0.2, x1lab = NULL, x2lab = NULL, label = ytrain) {
  dd <- data.frame(x1, x2, label)
  pp <-
    ggplot(data = dd, aes(x = x1, y = x2, label = label, color = as.factor(label))) +
    geom_point(size = point_size, position = "jitter") +
    theme_bw() +
    theme(
      legend.position = "none",
      axis.line = element_line(colour = "black"),
      # panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      # panel.border = element_blank()
      panel.background = element_blank()
    ) +
    labs(y = x2lab, x = x1lab)
  return(pp)
}

plot_prob <- function(x1, x2, point_size = 0.2, x1lab = NULL, x2lab = NULL, prob) {
  dd <- data.frame(x1, x2, prob)
  pp <-
    ggplot(data = dd, aes(x = x1, y = x2, color = prob)) +
    geom_point(size = point_size, position = "jitter") +
    theme_bw() +
    theme(
      legend.position = "none",
      axis.line = element_line(colour = "black"),
      # panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      # panel.border = element_blank()
      panel.background = element_blank()
    ) +
    labs(y = x2lab, x = x1lab)
  return(pp)
}

mylogit <- function(x) {
  eps <- 10^(-100)
  log(x + eps) / log(1 - x - eps)
}
#+end_src

#+RESULTS:

This is a function to calculate weighted log loss using caret's train object.
#+begin_src R
caret_wlogloss <- function(data, pos = "cor", neg = "no_cor", cut = 0.5) {
  ff <- data$Resample
  obs <- 1 * (data$obs == pos)
  prob <- data[[pos]]
  pred <- 1 * (prob > cut)
  if (is.null(data$weights)) {
    ww <- rep(1, length(pred))
  } else {
    ww <- data$weights
  }

  return(wlogloss(y = obs, p = prob, w = ww))
}
#+end_src

#+RESULTS:

This is a function to calculate weighted F1 score using caret's train object.
#+begin_src R
caret_wf1 <- function(data, cut = 0.5) {
  ff <- data$Resample
  obs <- 1 * (data$obs == "above50k")
  prob <- data$above50k
  pred <- 1 * (prob > cut)
  if (is.null(data$weights)) {
    ww <- rep(1, length(pred))
  } else {
    ww <- data$weights
  }

  ww <- ww / sum(ww)
  TP <- sum(1 * ww * (pred == 1 & obs == 1))
  FP <- sum(1 * ww * (pred == 1 & obs == 0))
  TN <- sum(1 * ww * (pred == 0 & obs == 0))
  FN <- sum(1 * ww * (pred == 0 & obs == 1))

  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  f1 <- 2 * precision * recall / (precision + recall)
  return(list(precision = precision, recall = recall, f1 = f1))
}
#+end_src

#+RESULTS:

- =ssbar=: to create a side by side barplot of a categorical variable for each cluster
#+begin_src R
ssbar <- function(varn, cc) {
  out <- list()
  tf <- wtd.table(cl, varn, weights = sweight) / gw
  wc <- which(apply(tf, 2, sum) < cc)
  Other <- tf[, wc]
  Other <- apply(Other, 1, sum)
  if (length(wc) > 0) {
    tf <- tf[, -wc]
    out$table <- cbind(tf, Other)
  } else {
    out$table <- tf
  }

  tf <- as.data.frame(tf)
  of <- data.frame(Var1 = 1:K, Var2 = rep("Other", K), Freq = Other)
  tf <- rbind(tf, of)

  colnames(tf) <- c("Cluster", "Category", "Conditional.Frequency")
  pp <- ggplot(tf, aes(Cluster, Conditional.Frequency, fill = Category)) +
    geom_bar(position = "dodge", stat = "identity")
  out$plot <- pp
  return(out)
}
#+end_src

#+RESULTS:


#+begin_src R
## row.names(vimp) should be variable names
## vimp should be p by 1 (matrix, array, or data.frame)

require(ggplot2)
plot_vimp <- function(vimp, cutoff = 1) {
  tryCatch(
    {
      if (dim(vimp)[1] < dim(vimp)[2]) vimp <- t(vimp)
    },
    error = function(e) {
      stop("vimp should be a p by 1 matrix, array, or data.frame.")
    }
  )

  ## Get the relative importance
  mval <- max(vimp[, 1])
  vimp[, 2] <- (vimp[, 1] / mval) * 100

  cid <- vimp[, 2] > cutoff
  rnimp <- vimp[, 2][cid]
  imp.var <- row.names(vimp)[cid]

  imp.dat <- data.frame(imp.var, rnimp)

  ## barplot of relative importance
  gg <- ggplot(data = imp.dat, aes(x = reorder(imp.var, rnimp), y = rnimp, fill = TRUE)) +
    ylab("Relative importance") +
    xlab("Feature") +
    geom_bar(stat = "identity", size = 3, width = 0.5) +
    coord_flip() +
    scale_fill_discrete(guide = FALSE) +
    theme_bw() +
    theme(
      axis.line = element_line(colour = "black"),
      text = element_text(size = 20),
      axis.text = element_text(size = 15),
      ## panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      ## panel.border = element_blank()
      panel.background = element_blank()
    )
  return(gg)
}
#+end_src

#+RESULTS:

#+begin_src R
## Define the predictive function
yhat <- function(X.model, newdata) {
  pp <- as.numeric(predict(X.model, newdata)$predictions[, 2])
  eps <- .Machine$double.eps
  out <- log((pp + eps) / (1 - pp + eps))
  return(out)
}
#+end_src

#+RESULTS:

* Preprocess V2
:PROPERTIES:
:header-args:R: :tangle preprocess_V2.R
:END:

This pre-processing includes a new data set for landuse and other infomation. Also, it includes contract type and vendor name as covariates.

#+begin_src R :results none
library("magrittr")
library(dplyr)
dpro <- readr::read_csv(file = "data/FDOT_10mi_Coordinates.csv", col_names = T)
names(dpro) <- make.names(names(dpro))

dgis <- readr::read_csv(file = "data/FDOT_10mi_Coordinates_coordinate_tab.csv", col_names = T)
names(dgis) <- make.names(names(dgis))

drural <- readr::read_csv(file = "data/FDOT_10mi_Coordinate_03022021_rural.csv", col_names = T)
names(drural) <- make.names(names(drural))

if (identical(dpro$pjt_id, dgis$Contract_ID)) {
  dpro$x <- dgis$Longitude
  dpro$y <- dgis$Latitude
}

if (identical(dpro$pjt_id, drural$Contract_ID)) {
  temp <- drural %>%
    mutate(pjt_id = Contract_ID) %>%
    select(pjt_id, u_r, Contract_Type, landuse_code, Landuse_lv_1, Landuse_lv_2, ROAD_DIREC, DISTRICT, COUNTYDOT, MNG_DIST, Vendor_Name)
  dpro <- plyr::join(dpro, temp)
}

dpro$railcross[is.na(dpro$railcross)] <- 0
dpro$bridge[is.na(dpro$bridge)] <- 0
dpro <- na.omit(dpro)

coef <- exp(c(0, -1 / 2, -1))
coef <- coef / sum(coef)

dd <- dpro %>%
  mutate(unemp = coef[1] * get(paste0("unemp_", start_yr)) +
    coef[2] * get(paste0("unemp_", start_yr - 1)) +
    coef[3] * get(paste0("unemp_", start_yr - 2))) %>%
  mutate(avg_temp = coef[1] * get(paste0("avg_temp_", start_yr)) +
    coef[2] * get(paste0("avg_temp_", start_yr - 1)) +
    coef[3] * get(paste0("avg_temp_", start_yr - 2))) %>%
  mutate(max_temp = coef[1] * get(paste0("max_temp_", start_yr)) +
    coef[2] * get(paste0("max_temp_", start_yr - 1)) +
    coef[3] * get(paste0("max_temp_", start_yr - 2))) %>%
  mutate(prec = coef[1] * get(paste0("prec_", start_yr)) +
    coef[2] * get(paste0("prec_", start_yr - 1)) +
    coef[3] * get(paste0("prec_", start_yr - 2))) %>%
  mutate(gdp = coef[1] * get(paste0("gdp_", start_yr)) +
    coef[2] * get(paste0("gdp_", start_yr - 1)) +
    coef[3] * get(paste0("gdp_", start_yr - 2))) %>%
  select(-c(roadway, start_yr, end_yr))

cnames <- names(dd)

no_drop <- !grepl("gdp_.", cnames) &
  !grepl("prec_.", cnames) &
  !grepl("max_temp_.", cnames) &
  !grepl("avg_temp_.", cnames) &
  !grepl("unemp_.", cnames)
#+end_src

#+begin_src R :results none
## df = dd[no_drop] %>% filter(pjt_type=="X3-Resurfacing")
df <- dd[no_drop]
df$logy <- log(df$modified_amounts) - log(df$orig_amounts)

df$pjt_type <- as.factor(df$pjt_type)
df$road_side <- as.factor(df$road_side)
df$funclass <- as.factor(df$funclass)
df$access_con <- as.factor(df$access_con)
df$Contract_Type <- as.factor(df$Contract_Type)
df$Vendor_Name <- as.factor(df$Vendor_Name)
cat_df <- df %>% select(pjt_type, road_side, funclass, access_con, Contract_Type, Vendor_Name)

df <- df %>%
  mutate(ncat_pjt_type = as.numeric(pjt_type)) %>%
  mutate(ncat_road_side = as.numeric(road_side)) %>%
  mutate(ncat_funclass = as.numeric(funclass)) %>%
  mutate(ncat_access_con = as.numeric(access_con)) %>%
  mutate(ncat_Contract_Type = as.numeric(Contract_Type)) %>%
  mutate(ncat_Vendor_Name = as.numeric(Vendor_Name)) %>%
  select(-c(pjt_type, road_side, funclass, access_con, Contract_Type, Vendor_Name))

dx <- df %>% select(-c(pjt_id, x, y, cor, sor, modified_days, actual_days, modified_amounts, logy, actual_amounts))
dxx <- dx %>%
  select(-c(ncat_pjt_type, ncat_road_side, ncat_funclass, ncat_access_con, ncat_Contract_Type, ncat_Vendor_Name)) %>%
  cbind(cat_df)

X <- model.matrix(~ 0 + ., dxx)
vn <- colnames(X) <- colnames(X) %>% make.names()

cory <- 1 * (df$logy > 0)
sory <- log(df$modified_days - df$orig_days + 1) - log(df$orig_days)
#+end_src

* Preprocess Rural
:PROPERTIES:
:header-args:R: :tangle preprocess_rural.R
:END:

This pre-processing aims to predict =urban_rural= varible.

#+begin_src R :results none
library("magrittr")
library(dplyr)
dpro <- readr::read_csv(file = "data/FDOT_10mi_Coordinates.csv", col_names = T)
names(dpro) <- make.names(names(dpro))

dgis <- readr::read_csv(file = "data/FDOT_10mi_Coordinates_coordinate_tab.csv", col_names = T)
names(dgis) <- make.names(names(dgis))

drural <- readr::read_csv(file = "data/FDOT_10mi_Coordinate_03022021_rural.csv", col_names = T)
names(drural) <- make.names(names(drural))

if (identical(dpro$pjt_id, dgis$Contract_ID)) {
  dpro$x <- dgis$Longitude
  dpro$y <- dgis$Latitude
}

if (identical(dpro$pjt_id, drural$Contract_ID)) {
  temp <- drural %>%
    mutate(pjt_id = Contract_ID) %>%
    select(pjt_id, u_r, Contract_Type, landuse_code, Landuse_lv_1, Landuse_lv_2, ROAD_DIREC, DISTRICT, COUNTYDOT, MNG_DIST, Vendor_Name)
  dpro <- plyr::join(dpro, temp)
}

dpro$railcross[is.na(dpro$railcross)] <- 0
dpro$bridge[is.na(dpro$bridge)] <- 0
dpro <- na.omit(dpro)
#+end_src

#+begin_src R :results none
## dd <- dpro %>% select(-c(roadway, start_yr,  end_yr)) %>%
##   mutate(mov_unemp = 0.6*unemp_2019 + 0.3*unemp_2018 + 0.1*unemp_2017 ) %>%
##   mutate(mov_avg_temp = 0.6*avg_temp_2019 + 0.3*avg_temp_2018 + 0.1*avg_temp_2017 ) %>%
##   mutate(mov_max_temp = 0.6*max_temp_2019 + 0.3*max_temp_2018 + 0.1*max_temp_2017 ) %>%
##   mutate(mov_prec = 0.6*prec_2019 + 0.3*prec_2018 + 0.1*prec_2017 ) %>%
##   mutate(mov_gdp = 0.6*gdp_2018 + 0.3*gdp_2017 + 0.1*gdp_2016 )

coef <- exp(c(0, -1 / 2, -1))
coef <- coef / sum(coef)

dd <- dpro %>%
  mutate(unemp = coef[1] * get(paste0("unemp_", start_yr)) +
    coef[2] * get(paste0("unemp_", start_yr - 1)) +
    coef[3] * get(paste0("unemp_", start_yr - 2))) %>%
  mutate(avg_temp = coef[1] * get(paste0("avg_temp_", start_yr)) +
    coef[2] * get(paste0("avg_temp_", start_yr - 1)) +
    coef[3] * get(paste0("avg_temp_", start_yr - 2))) %>%
  mutate(max_temp = coef[1] * get(paste0("max_temp_", start_yr)) +
    coef[2] * get(paste0("max_temp_", start_yr - 1)) +
    coef[3] * get(paste0("max_temp_", start_yr - 2))) %>%
  mutate(prec = coef[1] * get(paste0("prec_", start_yr)) +
    coef[2] * get(paste0("prec_", start_yr - 1)) +
    coef[3] * get(paste0("prec_", start_yr - 2))) %>%
  mutate(gdp = coef[1] * get(paste0("gdp_", start_yr)) +
    coef[2] * get(paste0("gdp_", start_yr - 1)) +
    coef[3] * get(paste0("gdp_", start_yr - 2))) %>%
  select(-c(roadway, start_yr, end_yr))

cnames <- names(dd)

no_drop <- !grepl("gdp_.", cnames) &
  !grepl("prec_.", cnames) &
  !grepl("max_temp_.", cnames) &
  !grepl("avg_temp_.", cnames) &
  !grepl("unemp_.", cnames)
#+end_src

#+begin_src R :results none
## df = dd[no_drop] %>% filter(pjt_type=="X3-Resurfacing")
df <- dd[no_drop]
df$logy <- log(df$modified_amounts) - log(df$orig_amounts)

df$pjt_type <- as.factor(df$pjt_type)
df$road_side <- as.factor(df$road_side)
df$funclass <- as.factor(df$funclass)
df$access_con <- as.factor(df$access_con)
df$Contract_Type <- as.factor(df$Contract_Type)
df$Vendor_Name <- as.factor(df$Vendor_Name)
cat_df <- df %>% select(pjt_type, road_side, funclass, access_con, Contract_Type, Vendor_Name)

df <- df %>%
  mutate(ncat_pjt_type = as.numeric(pjt_type)) %>%
  mutate(ncat_road_side = as.numeric(road_side)) %>%
  mutate(ncat_funclass = as.numeric(funclass)) %>%
  mutate(ncat_access_con = as.numeric(access_con)) %>%
  mutate(ncat_Contract_Type = as.numeric(Contract_Type)) %>%
  mutate(ncat_Vendor_Name = as.numeric(Vendor_Name)) %>%
  select(-c(pjt_type, road_side, funclass, access_con, Contract_Type, Vendor_Name))

dx <- df %>% select(-c(pjt_id, x, y, cor, sor, modified_days, actual_days, modified_amounts, logy, actual_amounts, u_r))
dxx <- dx %>%
  select(-c(ncat_pjt_type, ncat_road_side, ncat_funclass, ncat_access_con, ncat_Contract_Type, ncat_Vendor_Name)) %>%
  cbind(cat_df)

X <- model.matrix(~ 0 + ., dxx)
vn <- colnames(X) <- colnames(X) %>% make.names()

cory <- 1 * (df$logy > 0)
sory <- log(df$modified_days - df$orig_days + 1) - log(df$orig_days)
y <- df$u_r
#+end_src

* Tune&Train base models
We have three base models. Each model has been tuned using 4 fold-cross
validation. Since we aim to train a super learner instead of simple blend of
base models, predctions collected from CV should be passed to the super learner.
The CV-folds should be consistent for all models.

#+begin_src R :tangle cor_train_base_prepro.R
xtrain <- model.matrix(~ 0 + ., data = dx)
ytrain <- 1 * (y > 0)
weights <- rep(1, length(y)) / length(y)

set.seed(1)
nfold <- 4
shu <- sample(1:length(ytrain))
xtrain <- xtrain[shu, ]
ytrain <- ytrain[shu]
data_folds <- caret::createFolds(ytrain, k = nfold)
#+end_src

#+RESULTS:

** ranger
:PROPERTIES:
:ID:       1ca7e343-cebd-4315-82c7-336e1960bd5b
:END:
An R package ranger is used to train the random forest. An R pacakge caret is a
wrapper of many R packages, which we will use for training. The below is caret's model training parameters.
#+begin_src R :tangle cor_train_ranger.R
my_tr <- trainControl(
  method = "cv",
  number = nfold,
  classProbs = TRUE,
  savePredictions = "all",
  ## summaryFunction = twoClassSummary, # AUC
  ## ,summaryFunction = prSummary # PR-AUC
  ## ,summaryFunction = fSummary # F1
  summaryFunction = mnLogLoss,
  search = "random",
  verboseIter = TRUE,
  allowParallel = TRUE,
  indexOut = data_folds
)
#+end_src

#+RESULTS:

Unlike CatBoost or XGBoost, ranger doesn't have an internal handling mecahnism
of missing values.
#+begin_src R :tangle cor_train_ranger.R
## imputation needs for ranger
ixtrain <- xtrain
ixtrain[is.na(ixtrain)] <- -99

## above50k needs to be "positive"
## caret considers 1st class as "positive" class
fytrain <- factor(ytrain)
levels(fytrain) <- c("no_cor", "cor")
#+end_src

#+RESULTS:

- Tuned hyperparameters of ranger.
#+begin_src R :tangle cor_train_ranger.R
ranger_grid <- expand.grid(
  mtry = c(5,10,15,20,25,30),
  splitrule = "gini",
  min.node.size = c(5,10,15,20)
)
#+end_src

#+RESULTS:

The below is for CV and saving a final model.
#+begin_src R :tangle cor_train_ranger.R
set.seed(1)
ranger_tune <- train(
  x = ixtrain, y = fytrain,
  method = "ranger",
  trControl = my_tr,
  tuneGrid = ranger_grid,
  weights = weights,
  preProc = NULL,
  importance = "impurity",
  num.trees = 500)

temp <- ranger_tune$pred$co
ranger_id <- ranger_tune$pred$rowIndex
ranger_prob <- temp[order(ranger_id)]
ranger_final <- ranger_tune$finalModel
ranger_imp <- varImp(ranger_tune)$importance
#+end_src

=ranger= gives the confusion matrix if =probability= is set to =FALSE=.

#+name: ranger_full_training
#+begin_src R :tangle cor_train_pimp_rf.R
set.seed(9999)
mydd = data.frame(y=fytrain, ixtrain)

## to calulate importance p-value based on purmutation
ranger_ff <- ranger(y~.,data = mydd,
                       num.trees = 500, mtry = 25,
  ## importance = "impurity_corrected",
  importance = "permutation",
  ## importance = "hold-out",
  ## importance = "impurity",
  write.forest = TRUE,
  probability = TRUE,
  min.node.size = 5,
  class.weights = NULL, splitrule = "gini", classification = TRUE,
  seed = 99
)

ranger_ho <- holdoutRF(y~.,data = mydd,
                       num.trees = 500, mtry = 25,
  ## importance = "impurity_corrected",
  ## importance = "permutation",
  ## importance = "hold-out",
  ## importance = "impurity",
  write.forest = TRUE,
  probability = TRUE,
  min.node.size = 5,
  class.weights = NULL, splitrule = "gini", classification = TRUE,
  seed = 99
)
#+end_src

#+begin_src R :tangle cor_train_pimp_rf.R
ranger_imp <- ranger_ff$variable.importance
rtemp <- data.frame(ranger_imp = ranger_imp)
row.names(rtemp) <- names(ranger_imp)
rrtemp <- rtemp %>%
  arrange(-ranger_imp) %>%
  slice(1:15)
rrtemp[,1] = rrtemp[,1] / rrtemp[1,1] * 100
rrtemp %>% knitr::kable()
#+end_src

#+RESULTS:
#+begin_example


|                  | ranger_imp|
|:-----------------|----------:|
|orig_amounts      | 100.000000|
|orig_days         |  31.882296|
|comm_out_state    |   5.297970|
|no_lane           |   3.310077|
|ind_other         |   2.865495|
|ind_agri          |   2.824632|
|pop_16yrover      |   2.652817|
|aadt              |   2.651760|
|comm_pubtransport |   2.357990|
|ind_manuf         |   2.231341|
|inde_ed_meds      |   1.812139|
|ind_transport     |   1.779970|
|med_ind_income    |   1.724870|
|worker_med_age    |   1.502841|
|gdp               |   1.479755|
#+end_example

#+begin_src R :tangle cor_train_pimp_rf.R
set.seed(9999)
im_pp = importance_pvalues(ranger_ff, method = "altmann", formula = y ~ ., data = mydd,
                                  num.permutations = 200)
pimp = sort(im_pp[,2])[1:15]
pimp %>% knitr::kable()
pimp_vv = names(pimp)[pimp < 0.1]
#+end_src

#+RESULTS:
#+begin_example


|                  |         x|
|:-----------------|---------:|
|orig_days         | 0.0049751|
|orig_amounts      | 0.0049751|
|no_lane           | 0.0248756|
|comm_out_state    | 0.0447761|
|MNG_DIST          | 0.0597015|
|avg_temp          | 0.0696517|
|ind_other         | 0.0746269|
|pop_16yrover      | 0.0845771|
|ind_agri          | 0.0945274|
|comm_pubtransport | 0.0995025|
|ind_manuf         | 0.1144279|
|ncat_pjt_type     | 0.1144279|
|aadt              | 0.1243781|
|inde_ed_meds      | 0.1243781|
|gdp               | 0.1243781|
#+end_example

#+begin_src R :tangle cor_train_pimp_rf.R
set.seed(9999)
mydd = data.frame(y=fytrain, ixtrain[, pimp_vv])
set.seed(1)
pimp_rf_tune <- train(
  y = fytrain, x =  ixtrain[, pimp_vv],
  method = "ranger",
  trControl = my_tr,
  tuneGrid = expand.grid(
  mtry = c(2,4,6,8,10),
  splitrule = "gini",
  min.node.size = c(5,10,15,20)),
  weights = weights,
  preProc = NULL,
  importance = "impurity",
  num.trees = 500)


## to calulate importance p-value based on purmutation
pimp_rf <- ranger(y~.,data = mydd,
                       num.trees = 500, mtry = 8,
  ## importance = "impurity_corrected",
  importance = "permutation",
  ## importance = "hold-out",
  ## importance = "impurity",
  write.forest = TRUE,
  probability = TRUE,
  min.node.size = 5,
  class.weights = NULL, splitrule = "gini", classification = TRUE,
  seed = 99
)

#+end_src

#+RESULTS: ranger_full_training

#+begin_src R
saveRDS(pimp_rf, "cor_ranger_pimp_rf.rds")
#+end_src

#+RESULTS:

#+begin_src R :tangle cor_train_ranger_final.R
saveRDS(ranger_ff, "cor_ranger_rural_ff.rds")
#+end_src

#+RESULTS:

The below is to save urban prediction model. the predicted probablity will be used for cor prediction!
#+begin_src R
saveRDS(ranger_final, "cor_ranger_pred_rural.rds")
#+end_src

#+RESULTS:

#+begin_src R :results replace :tangle no
caret_wlogloss(ranger_tune$pred)
#+end_src

#+RESULTS:
: [1] 0.316729

#+begin_src R :results replace :tangle no
mean(ranger_tune$resample[, 1]) # incorrect. not using weight
#+end_src

#+RESULTS:
: [1] 0.3166399

*** test data
#+begin_src R :tangle test_prediction.R
if (TEST_SET) {
  ranger_final <- readRDS("ranger_final.rds")
  ixtest <- xtest
  ixtest[is.na(ixtest)] <- -99
  ranger_test_prob <- predict(ranger_final, ixtest)$predictions[, 1]
}
#+end_src

To create a meat-feature of the super learner for the test data.
* [2021-03-03 Wed] Urbanization :noexport:
:PROPERTIES:
:header-args:R: :exports results :noweb yes :eval never-export
:END:
** Intro
A variable ~u_r~ indicates whether a project site is located in urban or rural area. It doesn't have significant contribution in our COR prediction model. Our current hypothesis is there exists some pathways that ~u_r~ affects the COR event.
Let $y = 1$ if ~u_r = 1~; 0 therwise. We will build a prediction model for $y$ to see if there exists dependency between =u_r= and other covariates in the COR prediction model. This could help us understand how COR depends on ~u_r~ thorugh other covariates. The same data analytic pipe line will be used as one empolyed for the COR prediction model.
** TL;DR
In the random forest (non-linear) model, =ind_agri=, =gdp=, =aadt= are covariates strongly assoicated with ~u_r~. In the logistic (linear) model, =aadt=, =speedlimit=, =comm_in_county=, =ind_agri=, =ind_info=, =ind_fin=, =ind_public=, =funclass4= are strongly associated.

** random forest (trained using =ranger=)
#+begin_src R :results none :async yes
source("prerequisite.R")
source("custom_function.R")
source("preprocess_rural.R")
y <- df$u_r
#+end_src

The OOB accuracy is 88.5% at the optimal threshold (0.48). The variable importance is listed below:
#+begin_src R :results drawer
ranger_final <- readRDS("cor_ranger_pred_rural.rds")
ranger_imp <- ranger_final$variable.importance
rtemp <- data.frame(ranger_imp = ranger_imp)
row.names(rtemp) <- names(ranger_imp)

rrtemp <- rtemp %>% arrange(-ranger_imp)
readr::write_csv(data.frame(vname = row.names(rrtemp), importance = unlist(rrtemp)), "../urban_imp.csv")
rrtemp <- rrtemp %>% slice(1:20)
rrtemp %>% knitr::kable()
#+end_src

#+RESULTS:
:results:


|                  | ranger_imp|
|:-----------------|----------:|
|orig_amounts      |  14.484918|
|orig_days         |   9.207095|
|comm_out_state    |   3.226608|
|urban_ranger      |   3.191710|
|aadt              |   2.437268|
|ind_other         |   2.205853|
|ind_agri          |   2.159914|
|pop_16yrover      |   2.117236|
|inde_ed_meds      |   1.968435|
|ncat_pjt_type     |   1.923995|
|comm_pubtransport |   1.789494|
|comm_etc          |   1.662098|
|aadt_truck        |   1.661247|
|comm_workhome     |   1.606221|
|worker_med_age    |   1.530445|
|ind_transport     |   1.509710|
|ind_public        |   1.492927|
|no_lane           |   1.473475|
|prec              |   1.463618|
|med_ind_income    |   1.413978|
:end:

|                          | =ranger imp= |
|--------------------------+--------------|
| =ind_agri=               |    10.644862 |
| =mean_per_capita_income= |    10.032323 |
| =landuse_code=           |     8.503915 |
| =Landuse_lv_2=           |     7.454759 |
| =Landuse_lv_1=           |     6.530188 |
| =med_ind_income=         |     5.588089 |
| =gdp=                    |     3.409578 |
| =aadt=                   |     3.282648 |
| =comm_bike=              |     3.086364 |
| =hhd_med_income=         |     2.308874 |
| =ind_public=             |     2.089788 |
| =ind_manuf=              |     2.018978 |
| =hhd_mean_income=        |     2.001834 |
| =ind_fin=                |     1.881349 |
| =ncat_funclass=          |     1.859067 |
| =ind_info=               |     1.707055 |
| =comm_workers_per_car=   |     1.601287 |
| =comm_workhome=          |     1.571071 |
| =comm_pubtransport=      |     1.461341 |
| =med_age=                |     1.360138 |


Roughly speaking, the variable importance indicates the contribution of each covariate in improving the model's performance. The top 10 variables listed below could affect the COR event in difference ways. e.g. linear, hyperbolic, piecewise linear, etc.
Three landuse variables are highly associated with the response. However, it doesn't appear significant in the COR model.

#+begin_quote :export none
'prediction.error': Overall out of bag prediction error. For
          classification this is the fraction of missclassified
          samples, for probability estimation the Brier score, for
          regression the mean squared error and for survival one minus
          Harrell's C-index.
#+end_quote

This below is the prediction error.

#+begin_src R
ranger_final$prediction.error
#+end_src

#+RESULTS:
: [1] 0.1150858

#+begin_src R :results code graphics file :file cor_ranger_vimp.png :width 700 :height 700
plot_vimp(rrtemp,2)
#+end_src

#+RESULTS:
[[file:cor_ranger_vimp.png]]

** optimal threshold                                              :noexport:
We use CV to estimate the weighted F1 score for each probability threshold. At
threshold = 0.5, we expect the weighted F1 = 0.934.
#+begin_src R
set.seed(1)
resample_stats <- thresholder(ranger_tune,
  threshold = seq(0.2, 0.8, by = 0.01),
  final = TRUE
)

ot <- resample_stats$prob_threshold[which.max(resample_stats$F1)]
max(resample_stats$F1)
ot
#+end_src

#+RESULTS:
: [1] 0.9580882
: [1] 0.48

** random forest: main effects
#+begin_src R
mip <- rtemp %>%
  arrange(desc(ranger_imp)) %>%
  slice(1:8)

mdx <- which(colnames(dx) %in% row.names(mip))
right <- data.frame(name = row.names(mip), vimp = mip[, 1])
left <- data.frame(name = colnames(dx)[mdx], mdx = mdx)

mdx <- merge(right, left) %>%
  arrange(desc(vimp)) %>%
  select(mdx) %>%
  unlist()
#+end_src

#+RESULTS:

Since the prediction model is not easily interpretable, we visualize main effects of eight covariates using accumulated local effects (ALE) proposed in https://arxiv.org/pdf/1612.08468;Visualizing
The below is a matrix of ALE plots: covariates in x-axis, logit of prediction probabilities in y-axis; the larger, the more likely to be urban.
#+begin_src R :results code graphics file :file cor_aleplot.png :width 700 :height 700
## Define the predictive function
dfx <- as.data.frame(dx)

## Calculate and plot the ALE main and second-order interaction effects of x1, x2, x3
par(mfrow = c(3, 3))
ALE.1 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[1], K = 30, NA.plot = TRUE)
ALE.2 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[2], K = 30, NA.plot = TRUE)
ALE.3 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[3], K = 30, NA.plot = TRUE)
ALE.4 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[4], K = 30, NA.plot = TRUE)
ALE.5 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[5], K = 30, NA.plot = TRUE)
ALE.6 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[6], K = 30, NA.plot = TRUE)
ALE.7 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[7], K = 30, NA.plot = TRUE)
ALE.8 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = mdx[8], K = 30, NA.plot = TRUE)
ALE.12 <- ALEPlot(dfx, ranger_final, pred.fun = yhat, J = c(mdx[1], mdx[2]), K = 20, NA.plot = TRUE)
## ALE.23=ALEPlot(dfx, ranger_final, pred.fun=yhat, J=c(mdx[2],mdx[3]), K=20, NA.plot = TRUE)
## ALE.31=ALEPlot(dfx, ranger_final, pred.fun=yhat, J=c(mdx[3],mdx[1]), K=20, NA.plot = TRUE)
#+end_src

#+RESULTS:
[[file:cor_aleplot.png]]

** mapping high COR events                                         :noexport:

#+begin_src R
xeq <- ALE.1$x.values[ALE.1$f.values > 0]
minx <- min(xeq)
maxx <- max(xeq)
df$ind_agri_hl <- 1 * (df$ind_agri >= minx)
#+end_src

#+RESULTS:

=aadt= might be associated with the location as well. high =aadt= nearby big cities / highway hub?
#+begin_src R
xeq <- ALE.7$x.values[ALE.7$f.values > 0]
minx <- min(xeq)
maxx <- max(xeq)
df$aadt_hl <- with(df, 1 * (aadt >= minx))
#+end_src

#+RESULTS:

=gdp= would also be highly associated with city / county level factor
#+begin_src R
xeq <- ALE.8$x.values[ALE.8$f.values > 0]
minx <- min(xeq)
maxx <- max(xeq)
df$gdp_hl <- with(df, 1 * (gdp >= minx))
#+end_src

#+RESULTS:

** spatial pattern
:PROPERTIES:
:header-args:R: :exports results :width 672 :height 672
:END:

#+begin_src R
  library(maps)
  library(mapdata)
  library(ggplot2)
  states <- map_data("state")
  counties <- map_data("county")
#+end_src

#+RESULTS:

#+begin_src R :results none
pred <- 1 * (pred > 0.5)
df$mis <- 1 * (pred != y)
df %>% filter(y > min(y))

fl_df <- subset(states, region == "florida")
fl_county <- subset(counties, region == "florida")

ditch_the_axes <- theme(
  axis.text = element_blank(),
  axis.line = element_blank(),
  axis.ticks = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.title = element_blank()
)

gg_base <- ggplot(data = fl_df, mapping = aes(x = long, y = lat, group = group)) +
  coord_fixed(1.3) +
  geom_polygon(color = "black", fill = "gray")
#+end_src

#+begin_src R
gg_base <- gg_base +
  geom_polygon(data = fl_county, fill = NA, color = "white") +
  geom_polygon(color = "black", fill = NA)
#+end_src

#+RESULTS:

#+begin_src R
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# To use for fills, add
## scale_fill_manual(values=cbPalette)

# To use for line and point colors, add
## scale_colour_manual(values=cbPalette)
#+end_src

#+RESULTS:


#+begin_src R :results none
load("col.pal.RData")
temp <- col.pal(10)
col_pal <- c(temp[1:2])

ov_map <- function(df, vname) {
  gg <- gg_base +
    geom_point(data = df, mapping = aes(x = x, y = y, group = var, colour = var), size = 2, alpha = 0.5) +
    scale_colour_manual(values = cbPalette) +
    labs(color = paste0(vname, "\n")) +
    ## scale_fill_gradient2() +
    theme_bw() +
    theme(text = element_text(size = 20)) +
    ## theme(legend.text = element_text(size = 10)) +
    ditch_the_axes
  print(gg)
  return(gg)
}
#+end_src

#+begin_src R :results none
ov_cont_map <- function(df, vname) {
  gg <- gg_base +
    geom_point(data = df, mapping = aes(x = x, y = y, group = NULL, colour = var), size = 2, alpha = 0.5) +
    scale_colour_gradientn(colours = rev(rainbow(3))) +
    ## scale_fill_manual(colours = cbPalette) +
    ## scale_colour_gradient2() +
    labs(color = paste0(vname, "\n")) +
    ## scale_colour_gradient2()+
    theme_bw() +
    theme(text = element_text(size = 20)) +
    ## theme(legend.text = element_text(size = 10)) +
    ## theme(legend.position="top") +
    ditch_the_axes
  print(gg)
  return(gg)
}
#+end_src

#+RESULTS:

*** urban sites

#+begin_src R :results graphics file :file urb_map.png
var <- factor(y, label = c("rural", "urban"))
df %>%
  mutate(var = var) %>%
  ov_map("classification")
#+end_src

#+RESULTS:
[[file:urb_map.png]]


*** main effect: =ind_agri=

#+begin_src R :results graphics file :file ind_agri_map.png
df %>%
  mutate(var = (281.5 - ind_agri)) %>%
  ov_cont_map("281.5 - ind_agri")
#+end_src

#+RESULTS:
[[file:ind_agri_map.png]]

*** main effect: =gdp=
#+begin_src R :results graphics file :file gdp_map.png
df %>%
  mutate(var = log(gdp)) %>%
  ov_cont_map("log(gdp)")
#+end_src

#+RESULTS:
[[file:gdp_map.png]]

*** main effect: =aadt=
#+begin_src R :results graphics file :file aadt_map.png
df %>%
  mutate(var = log(aadt)) %>%
  ov_cont_map("log(aadt)")
#+end_src

#+RESULTS:
[[file:aadt_map.png]]

** Logistic regression
In this section, the LASSO is used to select covariates. Then, the logistic regression to predict ~u_r~ is performed on the selected covariates. This is a generalized linear model. Roughly speaking, the log odds of =urban= is increased by "coefficient" when we increase the covariate by one unit. Please find covariates highly related to ~u_r~ and their "coefficient" values in the table below. This simple model shows decent accurary (86%) at 0.5 thereshold.

#+begin_src R :results drawer
m2 <- glm(y ~ aadt + speedlimit + comm_in_county + ind_agri + ind_info + ind_fin + ind_public + funclass4, data = as.data.frame(X), family = "binomial")
coef(m2) %>% knitr::kable()
#+end_src

|                  |          x |
|------------------+------------|
| (Intercept)      |  1.0836081 |
| =aadt=           |  0.0000467 |
| =speedlimit=     | -0.0764798 |
| =comm_in_county= |  0.0423719 |
| =ind_agri=       | -0.0182894 |
| =ind_info=       | -0.0007169 |
| =ind_fin=        |  0.0051434 |
| =ind_public=     | -0.0117294 |
| =funclass4=      | -1.3995172 |

#+begin_src R
pred <- predict(m2, newx = as.data.frame(X))
tab <- table(pred > 0, y)
## tab
print("Accuracy:")
sum(diag(tab)) / sum(tab)
#+end_src

#+RESULTS:
: [1] "Accuracy:"
: [1] 0.8600823

* [2021-04-01 Thu] COR analysis :export:
:PROPERTIES:
:header-args:R: :exports results :noweb yes
:END:
A prediction target variable: $y = 1$ if $\log COR > 0$; 0 otherwise, where
\[
COR = \frac{\text{original amounts} + \text{modified amounts}}{\text{original amounts}}
\]
We use the random forest to train the prediction model. The =R= package =ranger= is used for the training.
Moving average (three years backward from a project start year) covariates are generated and substituted with time series covariates.
#+begin_src R :results none :tangle cor-code-preproc.r
source("prerequisite.R")
source("custom_function.R")
source("preprocess_rural.R")
## to create urbanization index
y <- df$u_r
## y = 1 * (df$logy > 0)
#+end_src

The urban classification based on =landuse_lv_2= is not exclusive, so it cannot be used for the COR prediction model.
#+begin_src R :eval no
tt <- readr::read_csv("data/urban_index.csv")
udex <- numeric(nrow(df))
for (dd in 1:nrow(df)) {
  for (cc in 1:6) {
    if (df$Landuse_lv_2[dd] %in% unlist(tt[, cc])) {
      udex[dd] <- cc
    }
  }
}
#+end_src

Instead we the prediction probability of urbanization obtained from our earlier prediction model. The urbanization index training is done using RF with full training set. See [[id:1ca7e343-cebd-4315-82c7-336e1960bd5b][ranger]]
#+begin_src R :tangle cor-code-preproc.r
ranger_final <- readRDS("cor_ranger_pred_rural.rds")
## ranger_final <- readRDS("cor_ranger_rural_ff.rds")
## urban_ranger <- ranger_final$predictions[, 2]
rrdd = model.matrix(~ 0 + ., data = dx)
urban_ranger = predict(ranger_final, rrdd)$predictions[, 2]
## source("cor_train_base_prepro.R")
y <- 1 * (df$logy > 0)
dx[, "ncat_Vendor_Name"] <- NULL
## dx <- cbind(dx, urban_ranger)
dx <- data.frame(dx, u_r = df$u_r)
#+end_src

#+RESULTS:

- use vnames in col 2 and description in col 5-6
#+begin_src R :results silent
vdesc <- readr::read_csv("data/vardesc.csv")
vlist <- readr::read_csv("data/varlist.csv")
#+end_src

#+begin_src R :results silent :tangle cor-code-preproc.r
source("cor_train_base_prepro.R")
source("cor_train_ranger.R")
#+end_src

In a previous COR prediction model, an urbaniztion binary index has no significant effect in the model.
\[
P(urban_i = 1 | x_i) = f(x_i)
\]
\[\hat f(\mathbf{x}) > 0.5 \text{ you predict a site is "urban". } \] $\hat f(x)$ might be thought as an approximation of C1 - C6 stages in the urbanization.
$\hat f(\mathbf{x})$ is a function of existing covariates.
$x_{i}$, covariates (indenpendent variables), is used for both COR and urban prediction model.
$urban_i$, response (dependent variable), is a target variable for the urban prediction model. It is not included in $x_{i}$.

Now, we append the prediction probability into the original data set $\mathbf{x}$, and use $(\mathbf{x}, \hat f(\mathbf{x}))$ as covariate of the COR prediction model. Feature engineering!

** RF (trained using =ranger=)
We trained the COR prediction model using the appended data set (with feature engineering).
The OOB accuracy is 77.9% at the optimal threshold (0.5-ish?). The variable importance is listed below:
#+begin_src R :results drawer
ranger_imp <- pimp_rf$variable.importance
rtemp <- data.frame(ranger_imp = ranger_imp)
row.names(rtemp) <- names(ranger_imp)
rrtemp <- rtemp %>%
  arrange(-ranger_imp) %>%
  slice(1:10)
rrtemp %>% knitr::kable()
#+end_src

#+RESULTS:
:results:


|                  | ranger_imp|
|:-----------------|----------:|
|orig_amounts      |  0.0796520|
|orig_days         |  0.0221467|
|comm_out_state    |  0.0115002|
|pop_16yrover      |  0.0093243|
|ind_agri          |  0.0073639|
|no_lane           |  0.0054459|
|comm_pubtransport |  0.0042226|
|MNG_DIST          |  0.0028667|
|avg_temp          |  0.0015761|
|ind_other         |  0.0013101|
:end:

Roughly speaking, the variable importance indicates the contribution of each covariate in improving the model's performance. The top 10 variables listed below could affect the COR event in difference ways. e.g. linear, hyperbolic, piecewise linear, etc.

#+begin_quote
'prediction.error': Overall out of bag prediction error. For
          classification this is the fraction of missclassified
          samples, for probability estimation the Brier score, for
          regression the mean squared error and for survival one minus
          Harrell's C-index.
#+end_quote

#+begin_src R
1 - pimp_rf$prediction.error
#+end_src

#+RESULTS:
: [1] 0.8008818

In the below, =urban_ranger= represents $\hat f(x)$.
#+begin_src R :results code graphics file :file cor_ranger_vimp.png :width 700 :height 700
plot_vimp(rrtemp,2)
#+end_src

#+RESULTS:
[[file:cor_ranger_vimp.png]]

** optimal threshold                                              :noexport:
We use CV to estimate the weighted F1 score for each probability threshold. At
threshold = 0.5, we expect the weighted F1 = 0.934.
#+begin_src R
set.seed(1)
resample_stats <- thresholder(ranger_tune,
  threshold = seq(0.2, 0.8, by = 0.01),
  final = TRUE
)

ot <- resample_stats$prob_threshold[which.max(resample_stats$F1)]
max(resample_stats$F1)
ot
#+end_src

#+RESULTS:
: Error in thresholder(ranger_tune, threshold = seq(0.2, 0.8, by = 0.01),  :
:   object 'ranger_tune' not found
: Error: object 'resample_stats' not found
: Error: object 'resample_stats' not found
: Error: object 'ot' not found

** main effects
#+begin_src R
mip <- rtemp %>%
  arrange(desc(ranger_imp)) %>%
  slice(1:10)

mdx <- which(colnames(dx) %in% row.names(mip))
right <- data.frame(name = row.names(mip), vimp = mip[, 1])
left <- data.frame(name = colnames(dx)[mdx], mdx = mdx)

mdx <- merge(right, left) %>%
  arrange(desc(vimp)) %>%
  select(mdx) %>%
  unlist()
#+end_src

#+RESULTS:

Since the prediction model is not easily interpretable, we visualize main effects of eight covariates using accumulated local effects (ALE) and partial dependence (PD) plots proposed in https://arxiv.org/pdf/1612.08468;Visualizing
The below is a matrix of ALE plots: covariates in x-axis, logit of prediction probabilities in y-axis; the larger, the more likely to have COR. The last one describes interaction effects of =orig_amount= and =orig_days=.

#+begin_src R :results code graphics file :file cor_aleplot.png :width 700 :height 700
## Define the predictive function
dfx <- as.data.frame(dx)

## Calculate and plot the ALE main and second-order interaction effects of x1, x2, x3
par(mfrow = c(5, 3))
ALE.1 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[1], K = 15, NA.plot = TRUE)
ALE.2 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[2], K = 15, NA.plot = TRUE)
ALE.3 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[3], K = 15, NA.plot = TRUE)
ALE.4 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[4], K = 15, NA.plot = TRUE)
ALE.5 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[5], K = 15, NA.plot = TRUE)
ALE.6 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[6], K = 15, NA.plot = TRUE)
ALE.7 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[7], K = 15, NA.plot = TRUE)
ALE.8 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[8], K = 15, NA.plot = TRUE)
ALE.9 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[9], K = 15, NA.plot = TRUE)
ALE.10 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[10], K = 15, NA.plot = TRUE)
## ALE.12 <- ALEPlot(dfx, pimp_rf, pred.fun = yhat, J = c(mdx[1], mdx[2]), K = 20, NA.plot = TRUE)
## ALE.23=ALEPlot(dfx, pimp_rf, pred.fun=yhat, J=c(mdx[2],mdx[3]), K=20, NA.plot = TRUE)
## ALE.31=ALEPlot(dfx, pimp_rf, pred.fun=yhat, J=c(mdx[3],mdx[1]), K=20, NA.plot = TRUE)
#+end_src

#+RESULTS:
[[file:cor_aleplot.png]]

The below is a matrix of PD plot.
#+begin_src R :results code graphics file :file cor_pdplot.png :width 700 :height 700
## Calculate and plot the Asecond-order interaction effx2, x3
par(mfrow = c(3, 3))
PD.1 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[1], K = 30)
PD.2 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[2], K = 30)
PD.3 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[3], K = 30)
PD.4 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[4], K = 30)
PD.5 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[5], K = 30)
PD.6 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[6], K = 30)
PD.7 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[7], K = 30)
PD.8 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = mdx[8], K = 30)
PD.12 <- PDPlot(dfx, pimp_rf, pred.fun = yhat, J = c(mdx[1], mdx[2]), K = 20)
## PD.23=PDPlot(dfx, pimp_rf, pred.fun=yhat, J=c(mdx[2],mdx[3]), K=20)
## PD.31=PDPlot(dfx, pimp_rf, pred.fun=yhat, J=c(mdx[3],mdx[1]), K=20)
#+end_src

#+RESULTS:
[[file:cor_pdplot.png]]

** mapping high COR events                                         :noexport:
#+begin_quote
'predictions': Predicted classes/values, based on out of bag samples
          (classification and regression only).
#+end_quote

#+begin_src R
ff <- df %>%
  mutate(pred = pimp_rf$predictions[, 2]) %>%
  filter((orig_amounts >= min(ALE.1$x.values[ALE.1$f.values > 0]) & orig_days >= min(ALE.2$x.values[ALE.2$f.values > 0])) | (orig_amounts <= min(ALE.1$x.values[ALE.1$f.values > 0]) & orig_days <= min(ALE.2$x.values[ALE.2$f.values > 0])))

df$oram_hl <- 1 * (df$orig_amounts >= min(ALE.1$x.values[ALE.1$f.values > 0]))
df$orda_hl <- 1 * (df$orig_days >= min(ALE.2$x.values[ALE.2$f.values > 0]))

pred <- 1 * (pimp_rf$predictions[, 2] > 0.5)
mis <- df[pred != y, ]
hit <- df[pred == y, ]
#+end_src

#+RESULTS:

#+begin_src R
xmin <- min(df$x)
ymin <- min(df$y)
xmax <- max(df$x)
ymax <- max(df$y)

par(mfrow = c(2, 2))
plot(df$x, df$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
plot(mis$x, mis$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
plot(ff$x, ff$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
plot(hit$x, hit$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))

pred <- 1 * (pimp_rf$predictions[, 2] > 0.5)
sum(pred != y) / length(y)
#+end_src

#+RESULTS:
: [1] 0.473251

=comm_out_state= can take account for the spatial effect. It has high values when the site is located along with the state border. =com_low= contains high and low =comm_out_state=. high / low surfix is about the prediction value, not the variable value
#+begin_src R
xeq <- ALE.3$x.values[ALE.3$f.values > 0]
minx <- min(xeq)
maxx <- max(xeq)
com_high <- df %>% filter(comm_out_state <= maxx & comm_out_state >= minx)
com_low <- df %>% filter(comm_out_state > maxx | comm_out_state < minx)
df$com_hl <- 1 * (df$comm_out_state <= maxx & df$comm_out_state >= minx)

par(mfrow = c(2, 2))
plot(com_high$x, com_high$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
plot(com_low$x, com_low$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
#+end_src

#+RESULTS:

=aadt= might be associated with the location as well. high =aadt= nearby big cities / highway hub?
#+begin_src R
aadt_high <- df %>% filter(aadt > min(ALE.4$x.values[ALE.4$f.values > 0]))
aadt_low <- df %>% filter(aadt <= min(ALE.4$x.values[ALE.4$f.values > 0]))
df$aadt_hl <- with(df, 1 * (aadt > min(ALE.4$x.values[ALE.4$f.values > 0])))

par(mfrow = c(2, 2))
plot(aadt_high$x, aadt_high$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
plot(aadt_low$x, aadt_low$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
#+end_src

#+RESULTS:

=gdp= would also be highly associated with city / county level factor
#+begin_src R
xeq <- ALE.8$x.values[ALE.8$f.values > 0]
minx <- min(xeq)
maxx <- max(xeq)
gdp_high <- df %>% filter(gdp <= maxx & gdp >= minx)
gdp_low <- df %>% filter(gdp > maxx | gdp < minx)
df$gdp_hl <- with(df, 1 * (gdp <= maxx & gdp >= minx))

par(mfrow = c(2, 2))
plot(gdp_high$x, gdp_high$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
plot(gdp_low$x, gdp_low$y, cex = 0.5, xlim = c(xmin, xmax), ylim = c(ymin, ymax))
#+end_src

#+RESULTS:

** spatial pattern                                                 :noexport:
:PROPERTIES:
:header-args:R: :tangle mapping.r :exports results :width 672 :height 672
:END:

Questions to answer:
- Are there spatial pattern in COR?
- Are there spatial pattern in covariates?
- Does the prediction model take some spatial pattern into account?

#+begin_src R
  library(maps)
  library(mapdata)
  library(ggplot2)
  states <- map_data("state")
  counties <- map_data("county")
#+end_src

#+RESULTS:

#+begin_src R :results none
pred <- 1 * (pimp_rf$predictions[, 2] > 0.5)
df$mis <- 1 * (pred != y)
## df %>% filter(y > min(y))

fl_df <- subset(states, region == "florida")
fl_county <- subset(counties, region == "florida")

ditch_the_axes <- theme(
  axis.text = element_blank(),
  axis.line = element_blank(),
  axis.ticks = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.title = element_blank()
)

gg_base <- ggplot(data = fl_df, mapping = aes(x = long, y = lat, group = group)) +
  coord_fixed(1.3) +
  ## geom_polygon(color = "black", fill = "gray")
  geom_polygon(color = "black", fill = "white")
#+end_src

#+begin_src R
gg_base <- gg_base +
  geom_polygon(data = fl_county, fill = NA, color = "gray") +
  geom_polygon(color = "black", fill = NA)
#+end_src

#+RESULTS:

#+begin_src R
load("col.pal.RData")
temp <- col.pal(10)
col_pal <- c(temp[1:2])

ov_map <- function(df, vname, colkey = cbPalette) {
  gg <- gg_base +
    geom_point(data = df, mapping = aes(x = x, y = y, group = var, colour = var), size = 4, alpha = 0.7) +
    scale_colour_manual(values = colkey) +
    labs(color = vname) +
    ## scale_fill_gradient2() +
    theme_bw() +
    ditch_the_axes +
    theme(
      text = element_text(size = 15),
      ## axis.title = element_text(size = 15),
      panel.grid.minor = element_blank(),
      panel.background = element_blank()
      ## panel.border = element_blank()
      ## panel.grid.major = element_blank()
    ) +
      theme(legend.key.size = unit(1, 'cm'), #change legend key size
        legend.key.height = unit(1, 'cm'), #change legend key height
        legend.key.width = unit(1, 'cm'), #change legend key width
        legend.title = element_text(size=30), #change legend title font size
        legend.text = element_text(size=20), #change legend text font size
      ## legend.position = "bottom")
      legend.position = c(0.3,0.5))
  print(gg)
  return(gg)
}
#+end_src

#+RESULTS:

#+begin_src R
ov_cts_map <- function(df, vname, colkey = cbPalette,  autopick = TRUE, viridis = FALSE) {
  if (autopick) colkey = colkey[c(1, 2, 3, 4, 6)]
  gg <- gg_base +
    geom_point(data = df, mapping = aes(x = x, y = y, group = factor(var), color = var), size = 4, alpha = 0.7) +
    ## scale_colour_manual(values=cbPalette) +
    labs(color = vname) +
    #scale_color_continuous(type = "viridis")+
    #scale_color_gradientn(colors = colkey) +
    ## scale_fill_gradient2()+
    theme_bw() +
    ditch_the_axes +
    theme(
      text = element_text(size = 15),
      ## axis.title = element_text(size = 15),
      panel.grid.minor = element_blank(),
      panel.background = element_blank()
      ## panel.border = element_blank()
      ## panel.grid.major = element_blank()
    ) +
      theme(legend.key.size = unit(1, 'cm'), #change legend key size
        legend.key.height = unit(1, 'cm'), #change legend key height
        legend.key.width = unit(1, 'cm'), #change legend key width
        legend.title = element_text(size=30), #change legend title font size
        legend.text = element_text(size=20), #change legend text font size
        legend.position = c(0.3,0.5))
  if (viridis) gg = gg + scale_color_continuous(type = "viridis")
  else gg = gg + scale_color_gradientn(colors = colkey)
  print(gg)
  return(gg)
}

# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# To use for fills, add
## scale_fill_manual(values=cbPalette)

# To use for line and point colors, add
## scale_colour_manual(values=cbPalette)
#+end_src

* COMMENT Local Variables
# Local Variables:
# org-babel-default-header-args:R: ((:session . "*R-COR*") (:export . "both") (:results . "output replace") (:width . 700) (:height . 700))
# eval: (flyspell-mode -1)
# eval: (spell-fu-mode -1)
# End:
